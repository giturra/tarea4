{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../'); sys.path.append('../hashing')\n",
    "from hashing import PrimeHash\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DATA_DIR = 'casos_lhash'\n",
    "\n",
    "np.random.seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('casos_lhash/ordered_blocks_creciente.npy'),\n",
       " WindowsPath('casos_lhash/ordered_blocks_intercalado.npy'),\n",
       " WindowsPath('casos_lhash/ordered_blocks_intercalado_rand.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_1.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_1_oversize.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_3.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_3_oversize.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_quarter.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_quarter_oversize.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_random.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_random_oversize.npy'),\n",
       " WindowsPath('casos_lhash/random_2n_oversize.npy'),\n",
       " WindowsPath('casos_lhash/random_n.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_1.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_1_oversize.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_3.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_3_oversize.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_quarter.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_quarter_oversize.npy'),\n",
       " WindowsPath('casos_lhash/repeated_quarter_1.npy'),\n",
       " WindowsPath('casos_lhash/repeated_quarter_1_oversize.npy'),\n",
       " WindowsPath('casos_lhash/repeated_quarter_random.npy'),\n",
       " WindowsPath('casos_lhash/repeated_quarter_random_oversize.npy')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Path(DATA_DIR).iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos mejores y peores casos LinearHash\n",
    "\n",
    "Sea $th$, el tamaño de tabla hash en cada instancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "size_max = int(1e4)\n",
    "sizes = [i for i in range(10, size_max, size_max//4)]\n",
    "\n",
    "\n",
    "primes = [2, 211, 509, 743]\n",
    "l_hashes = []\n",
    "\n",
    "for i in range(4):\n",
    "    l_hashes.append(PrimeHash(size=sizes[i], p=primes[i], update_size=True))\n",
    "\n",
    "print(l_hashes)\n",
    "\n",
    "df = pd.DataFrame(columns=['hash', 'original_size', 'final_size', 'caso',\n",
    "                           'subcaso', 'caracteristica', 'oversize', 'comparaciones', 'tamano', 'tiempos', 'tiempo_total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secuencia de elementos ordenados\n",
    "\n",
    "Se crean las siguientes variaciones de secuencias:\n",
    "\n",
    "1. Secuencia ordenada creciente con paso de 1\n",
    "2. Secuencia ordenada creciente con paso de 3\n",
    "3. Secuencia ordenada creciente con paso de $\\frac{th}{4}$\n",
    "4. Secuencia ordenada creciente con paso de aleatorio entre 4 y $th$\n",
    "\n",
    "5. Un cuarto creciente, otro decreciente y bis (bloques aleatorios)\n",
    "6. 4 bloques crecientes independientes\n",
    "\n",
    "Ademas para cada una de estas, existen dos tamaño: el tamaño de la tabla y 3 veces el tamaño de la tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "casos_ordenados_steps = list(Path(DATA_DIR).glob('ordered_step*'))\n",
    "casos_ordenados_blocks = list(Path(DATA_DIR).glob('ordered_blocks*'))\n",
    "\n",
    "arr_casos_ordenados_steps = [\n",
    "    {caso.stem: np.load(caso, allow_pickle=True)} for caso in casos_ordenados_steps]\n",
    "\n",
    "arr_casos_ordenados_blocks = [\n",
    "    {caso.stem: np.load(caso, allow_pickle=True)} for caso in casos_ordenados_blocks]\n",
    "\n",
    "casos_ordenados_steps, casos_ordenados_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for caso in tqdm(arr_casos_ordenados_steps):\n",
    "    tipo_caso, arrs = list(caso.items())[0]\n",
    "    rows = []\n",
    "    \n",
    "    tipo_caso = tipo_caso.split('_')\n",
    "    \n",
    "    type_name = 'ordered'\n",
    "    \n",
    "    subtype = tipo_caso[1]\n",
    "    caracteristica = tipo_caso[2\n",
    "                              ]\n",
    "    if tipo_caso[-1] == 'oversize':\n",
    "        oversize = 1\n",
    "    else:\n",
    "        oversize = 0\n",
    "    \n",
    "    for arr in tqdm(arrs):\n",
    "        l_hashes = [PrimeHash(size=s, p=p, update_size=True) for s, p in zip(sizes, primes)]\n",
    "        for lh in tqdm(l_hashes):\n",
    "            lh.run_experiment(arr)\n",
    "            total_times, individual_times, original_size, final_size, comp = lh.get_results()\n",
    "\n",
    "            row = {\n",
    "                'hash': 'prime', \n",
    "                'original_size': original_size,\n",
    "                'final_size' : final_size,\n",
    "                'caso': type_name, \n",
    "                'subcaso' : subtype, \n",
    "                'caracteristica' : caracteristica, \n",
    "                'oversize' : oversize,\n",
    "                'comparaciones':comp,\n",
    "                'tamano': len(arr), \n",
    "                'tiempos': individual_times, \n",
    "                'tiempo_total': total_times\n",
    "            }\n",
    "            \n",
    "        rows.append(row)\n",
    "    df = df.append(pd.DataFrame(rows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('results_prime_ordered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('results_prime_ordered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for caso in tqdm(arr_casos_ordenados_blocks):\n",
    "    tipo_caso, arrs = list(caso.items())[0]\n",
    "    rows = []\n",
    "    \n",
    "    tipo_caso = tipo_caso.split('_')\n",
    "    \n",
    "    type_name = 'ordered'\n",
    "    \n",
    "    subtype = tipo_caso[1]\n",
    "    caracteristica = tipo_caso[2\n",
    "                              ]\n",
    "    if tipo_caso[-1] == 'oversize':\n",
    "        oversize = 1\n",
    "    else:\n",
    "        oversize = 0\n",
    "    \n",
    "    for arr in tqdm(arrs):\n",
    "        l_hashes = [PrimeHash(size=s, p=p, update_size=True) for s, p in zip(sizes, primes)]\n",
    "        for lh in tqdm(l_hashes):\n",
    "            lh.run_experiment(arr)\n",
    "            total_times, individual_times, original_size, final_size, comp = lh.get_results()\n",
    "\n",
    "            row = {\n",
    "                'hash': 'prime', \n",
    "                'original_size': original_size,\n",
    "                'final_size' : final_size,\n",
    "                'caso': type_name, \n",
    "                'subcaso' : subtype, \n",
    "                'caracteristica' : caracteristica, \n",
    "                'oversize' : oversize,\n",
    "                'comparaciones':comp,\n",
    "                'tamano': len(arr), \n",
    "                'tiempos': individual_times, \n",
    "                'tiempo_total': total_times\n",
    "            }\n",
    "            \n",
    "        rows.append(row)\n",
    "    df = df.append(pd.DataFrame(rows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('results_prime_ordered.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secuencia de elementos repetidos\n",
    "\n",
    "Se crean las siguientes variaciones de secuencias:\n",
    "\n",
    "1. Secuencia de 3 elementos repetidos con step de 1\n",
    "2. Secuencia de 3 elementos repetidos con step de 3\n",
    "3. Secuencia de 3 elementos repetidos con step de $\\frac{th}{4}$\n",
    "4. Secuencia de $\\frac{th}{4}$ elementos repetidos con step aleatorio entre 4 y $th$\n",
    "\n",
    "Ademas para cada una de estas, existen dos tamaño: el tamaño de la tabla y 3 veces el tamaño de la tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['hash', 'original_size', 'final_size', 'caso',\n",
    "                           'repeticiones', 'step_size', 'oversize', 'comparaciones', 'tamano', 'tiempos', 'tiempo_total'])\n",
    "\n",
    "casos_repetidos_3 = list(Path(DATA_DIR).glob('repeated_3*'))\n",
    "casos_repetidos_quarter = list(Path(DATA_DIR).glob('repeated_quarter*'))\n",
    "\n",
    "arr_casos_repetidos_3 = [{caso.stem: np.load(caso, allow_pickle=True)} for caso in casos_repetidos_3]\n",
    "arr_casos_repetidos_quarter = [{caso.stem: np.load(caso, allow_pickle=True)} for caso in casos_repetidos_quarter]\n",
    "\n",
    "casos_repetidos_3, casos_repetidos_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for caso in tqdm(arr_casos_repetidos_3):\n",
    "    tipo_caso, arrs = list(caso.items())[0]\n",
    "    rows = []\n",
    "    \n",
    "    tipo_caso = tipo_caso.split('_')\n",
    "    \n",
    "    type_name = 'repeated'\n",
    "    \n",
    "    num_repeats = tipo_caso[1]\n",
    "    step_size = tipo_caso[2]\n",
    "    \n",
    "    if tipo_caso[-1] == 'oversize':\n",
    "        oversize = 1\n",
    "    else:\n",
    "        oversize = 0\n",
    "    \n",
    "    for arr in tqdm(arrs):\n",
    "        l_hashes = [PrimeHash(size=s, p=p, update_size=True) for s, p in zip(sizes, primes)]\n",
    "        for lh in tqdm(l_hashes):\n",
    "            lh.run_experiment(arr)\n",
    "            total_times, individual_times, original_size, final_size, comp = lh.get_results()\n",
    "\n",
    "            row = {\n",
    "                'hash': 'prime', \n",
    "                'original_size': original_size,\n",
    "                'final_size' : final_size,\n",
    "                'caso': type_name, \n",
    "                'repeticiones' : num_repeats, \n",
    "                'step_size' : step_size, \n",
    "                'oversize' : oversize,\n",
    "                'comparaciones':comp,\n",
    "                'tamano': len(arr), \n",
    "                'tiempos': individual_times, \n",
    "                'tiempo_total': total_times\n",
    "            }\n",
    "            \n",
    "        rows.append(row)\n",
    "    df = df.append(pd.DataFrame(rows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('results_prime_repeated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for caso in tqdm(arr_casos_repetidos_quarter):\n",
    "#     tipo_caso, arrs = list(caso.items())[0]\n",
    "#     rows = []\n",
    "    \n",
    "#     tipo_caso = tipo_caso.split('_')\n",
    "    \n",
    "#     type_name = 'repeated'\n",
    "    \n",
    "#     num_repeats = tipo_caso[1]\n",
    "#     step_size = tipo_caso[2]\n",
    "    \n",
    "#     if tipo_caso[-1] == 'oversize':\n",
    "#         oversize = 1\n",
    "#     else:\n",
    "#         oversize = 0\n",
    "    \n",
    "#     for arr in tqdm(arrs):\n",
    "#         l_hashes = [LinearHash(size=s, update_size=True) for s in sizes]\n",
    "#         for lh in tqdm(l_hashes):\n",
    "#             lh.run_experiment(arr)\n",
    "#             total_times, individual_times, original_size, final_size = lh.get_results()\n",
    "\n",
    "#             row = {\n",
    "#                 'hash': 'lineal', \n",
    "#                 'original_size': original_size,\n",
    "#                 'final_size' : final_size,\n",
    "#                 'caso': type_name, \n",
    "#                 'repeticiones' : num_repeats, \n",
    "#                 'step_size' : step_size, \n",
    "#                 'oversize' : oversize,\n",
    "#                 'tamano': len(arr), \n",
    "#                 'tiempos': individual_times, \n",
    "#                 'tiempo_total': total_times\n",
    "#             }\n",
    "            \n",
    "#         rows.append(row)\n",
    "#     df = df.append(pd.DataFrame(rows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secuencia de elementos aleatorias\n",
    "\n",
    "Se crean las siguientes variaciones de secuencias:\n",
    "\n",
    "1. Secuencias aleatorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['hash', 'original_size', 'final_size', 'caso',\n",
    "                           'caracteristica', 'tamano', 'oversize', 'comparaciones', 'tiempos', \n",
    "                           'tiempo_total'])\n",
    "\n",
    "\n",
    "casos_rand = list(Path(DATA_DIR).glob('random*'))\n",
    "arr_casos_rand = [{caso.stem: np.load(caso, allow_pickle=True)} for caso in casos_rand]\n",
    "casos_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for caso in tqdm(arr_casos_rand):\n",
    "    tipo_caso, arrs = list(caso.items())[0]\n",
    "    rows = []\n",
    "    \n",
    "    tipo_caso = tipo_caso.split('_')\n",
    "    \n",
    "    type_name = 'random'\n",
    "    \n",
    "    caracteristica = tipo_caso[1]\n",
    "    \n",
    "    if tipo_caso[-1] == 'oversize':\n",
    "        oversize = 1\n",
    "    else:\n",
    "        oversize = 0\n",
    "        \n",
    "    for arr in tqdm(arrs):\n",
    "        p_hashes = [PrimeHash(size=s, p=p, update_size=True) for s, p in zip(sizes, primes)]\n",
    "        for dh in tqdm(p_hashes):\n",
    "            dh.run_experiment(arr)\n",
    "            total_times, individual_times, original_size, final_size, comp = dh.get_results()\n",
    "\n",
    "            row = {\n",
    "                'hash': 'lineal', \n",
    "                'original_size': original_size,\n",
    "                'final_size' : final_size,\n",
    "                'caso': tipo_caso, \n",
    "                'caracteristica': caracteristica,\n",
    "                'tamano': len(arr), \n",
    "                'oversize': oversize,\n",
    "                'comparaciones': comp, \n",
    "                'tiempos': individual_times, \n",
    "                'tiempo_total': total_times \n",
    "            }\n",
    "            \n",
    "        rows.append(row)\n",
    "    df = df.append(pd.DataFrame(rows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('results_prime_random.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}