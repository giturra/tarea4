{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:13:01.722976Z",
     "start_time": "2020-07-17T17:13:01.344584Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../'); sys.path.append('../hashing')\n",
    "from hashing import LinearHash\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DATA_DIR = 'casos_lhash'\n",
    "\n",
    "np.random.seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:13:01.734141Z",
     "start_time": "2020-07-17T17:13:01.724946Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('casos_lhash/ordered_blocks_creciente.npy'),\n",
       " WindowsPath('casos_lhash/ordered_blocks_intercalado.npy'),\n",
       " WindowsPath('casos_lhash/ordered_blocks_intercalado_rand.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_1.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_1_oversize.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_3.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_3_oversize.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_quarter.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_quarter_oversize.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_random.npy'),\n",
       " WindowsPath('casos_lhash/ordered_step_random_oversize.npy'),\n",
       " WindowsPath('casos_lhash/random_2n_oversize.npy'),\n",
       " WindowsPath('casos_lhash/random_n.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_1.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_1_oversize.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_3.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_3_oversize.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_quarter.npy'),\n",
       " WindowsPath('casos_lhash/repeated_3_quarter_oversize.npy'),\n",
       " WindowsPath('casos_lhash/repeated_quarter_1.npy'),\n",
       " WindowsPath('casos_lhash/repeated_quarter_1_oversize.npy'),\n",
       " WindowsPath('casos_lhash/repeated_quarter_random.npy'),\n",
       " WindowsPath('casos_lhash/repeated_quarter_random_oversize.npy')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(Path(DATA_DIR).iterdir())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentos mejores y peores casos LinearHash\n",
    "\n",
    "Sea $th$, el tama単o de tabla hash en cada instancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:13:01.754635Z",
     "start_time": "2020-07-17T17:13:01.740716Z"
    }
   },
   "outputs": [],
   "source": [
    "size_max = int(1e4)\n",
    "sizes = [i for i in range(10, size_max, size_max//4)]\n",
    "\n",
    "l_hashes = [LinearHash(size=s, update_size=True) for s in sizes]\n",
    "\n",
    "df = pd.DataFrame(columns=['hash', 'original_size', 'final_size', 'caso',\n",
    "                           'subcaso', 'caracteristica', 'oversize', 'comparaciones', 'tamano', 'tiempos', 'tiempo_total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T17:17:35.627426Z",
     "start_time": "2020-07-13T17:17:35.624205Z"
    }
   },
   "source": [
    "## Secuencia de elementos ordenados\n",
    "\n",
    "Se crean las siguientes variaciones de secuencias:\n",
    "\n",
    "1. Secuencia ordenada creciente con paso de 1\n",
    "2. Secuencia ordenada creciente con paso de 3\n",
    "3. Secuencia ordenada creciente con paso de $\\frac{th}{4}$\n",
    "4. Secuencia ordenada creciente con paso de aleatorio entre 4 y $th$\n",
    "\n",
    "5. Un cuarto creciente, otro decreciente y bis (bloques aleatorios)\n",
    "6. 4 bloques crecientes independientes\n",
    "\n",
    "Ademas para cada una de estas, existen dos tama単o: el tama単o de la tabla y 3 veces el tama単o de la tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:13:01.814387Z",
     "start_time": "2020-07-17T17:13:01.756422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([WindowsPath('casos_lhash/ordered_step_1.npy'),\n",
       "  WindowsPath('casos_lhash/ordered_step_1_oversize.npy'),\n",
       "  WindowsPath('casos_lhash/ordered_step_3.npy'),\n",
       "  WindowsPath('casos_lhash/ordered_step_3_oversize.npy'),\n",
       "  WindowsPath('casos_lhash/ordered_step_quarter.npy'),\n",
       "  WindowsPath('casos_lhash/ordered_step_quarter_oversize.npy'),\n",
       "  WindowsPath('casos_lhash/ordered_step_random.npy'),\n",
       "  WindowsPath('casos_lhash/ordered_step_random_oversize.npy')],\n",
       " [WindowsPath('casos_lhash/ordered_blocks_creciente.npy'),\n",
       "  WindowsPath('casos_lhash/ordered_blocks_intercalado.npy'),\n",
       "  WindowsPath('casos_lhash/ordered_blocks_intercalado_rand.npy')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casos_ordenados_steps = list(Path(DATA_DIR).glob('ordered_step*'))\n",
    "casos_ordenados_blocks = list(Path(DATA_DIR).glob('ordered_blocks*'))\n",
    "\n",
    "arr_casos_ordenados_steps = [\n",
    "    {caso.stem: np.load(caso, allow_pickle=True)} for caso in casos_ordenados_steps]\n",
    "\n",
    "arr_casos_ordenados_blocks = [\n",
    "    {caso.stem: np.load(caso, allow_pickle=True)} for caso in casos_ordenados_blocks]\n",
    "\n",
    "casos_ordenados_steps, casos_ordenados_blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:13:08.030749Z",
     "start_time": "2020-07-17T17:13:01.870110Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99f676ee6dc403982b3d76f1c942564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc72a3e4b91c4a53a300809a0f2f11e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eaa3bad6afa4112b026706884405a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d034a0e0584f3b9fef85fd3dee156a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ab96c5634040669b5207023b45f647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b59b58864a4a858f5634f5cb841bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0e5080943bcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0ml_hashes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mLinearHash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdate_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msizes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlh\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_hashes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mlh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mtotal_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindividual_times\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\tarea4\\hashing\\base_hashing.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[1;34m(self, list_to_insert)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_to_insert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m             \u001b[0mcomps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_comp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0minsert_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\tarea4\\hashing\\linear_hashing.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, element, return_comp)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mcalc_insert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minsertion_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeleted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minsertion_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcalc_insert\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hash_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minsertion_index\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for caso in tqdm(arr_casos_ordenados_steps):\n",
    "    tipo_caso, arrs = list(caso.items())[0]\n",
    "    rows = []\n",
    "    \n",
    "    tipo_caso = tipo_caso.split('_')\n",
    "    \n",
    "    type_name = 'ordered'\n",
    "    \n",
    "    subtype = tipo_caso[1]\n",
    "    caracteristica = tipo_caso[2]\n",
    "    if tipo_caso[-1] == 'oversize':\n",
    "        oversize = 1\n",
    "    else:\n",
    "        oversize = 0\n",
    "    \n",
    "    for idx, arr in tqdm(enumerate(arrs)):\n",
    "        l_hashes = [LinearHash(size=s, update_size=True) for s in sizes]\n",
    "        for lh in tqdm(l_hashes):\n",
    "            lh.run_experiment(arr)\n",
    "            total_times, individual_times, original_size, final_size, comp = lh.get_results()\n",
    "\n",
    "            row = {\n",
    "                'hash': 'lineal', \n",
    "                'original_size': original_size,\n",
    "                'final_size' : final_size,\n",
    "                'caso': type_name, \n",
    "                'subcaso' : subtype, \n",
    "                'caracteristica' : caracteristica, \n",
    "                'oversize' : oversize,\n",
    "                'comparaciones':comp,\n",
    "                'tamano': len(arr), \n",
    "                'tiempos': individual_times, \n",
    "                'tiempo_total': total_times\n",
    "            }\n",
    "            \n",
    "        rows.append(row)\n",
    "    df = df.append(pd.DataFrame(rows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:13:08.051542Z",
     "start_time": "2020-07-17T17:13:08.038209Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('results_linear_ordered.csv')['comparaciones'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-17T17:13:08.099206Z",
     "start_time": "2020-07-17T17:13:08.055992Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('results_linear_ordered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T01:51:23.175469Z",
     "start_time": "2020-07-15T01:51:23.157594Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('results_linear_ordered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T02:31:34.599158Z",
     "start_time": "2020-07-15T01:56:00.881830Z"
    }
   },
   "outputs": [],
   "source": [
    "for caso in tqdm(arr_casos_ordenados_blocks):\n",
    "    tipo_caso, arrs = list(caso.items())[0]\n",
    "    rows = []\n",
    "    \n",
    "    tipo_caso = tipo_caso.split('_')\n",
    "    \n",
    "    type_name = 'ordered'\n",
    "    \n",
    "    subtype = tipo_caso[1]\n",
    "    caracteristica = tipo_caso[2\n",
    "                              ]\n",
    "    if tipo_caso[-1] == 'oversize':\n",
    "        oversize = 1\n",
    "    else:\n",
    "        oversize = 0\n",
    "    \n",
    "    for arr in tqdm(arrs[2:]):\n",
    "        l_hashes = [LinearHash(size=s, update_size=True) for s in sizes]\n",
    "        for lh in tqdm(l_hashes):\n",
    "            lh.run_experiment(arr)\n",
    "            total_times, individual_times, original_size, final_size, comp = lh.get_results()\n",
    "\n",
    "            row = {\n",
    "                'hash': 'lineal', \n",
    "                'original_size': original_size,\n",
    "                'final_size' : final_size,\n",
    "                'caso': type_name, \n",
    "                'subcaso' : subtype, \n",
    "                'caracteristica' : caracteristica, \n",
    "                'oversize' : oversize,\n",
    "                'comparaciones':comp,\n",
    "                'tamano': len(arr), \n",
    "                'tiempos': individual_times, \n",
    "                'tiempo_total': total_times\n",
    "            }\n",
    "            \n",
    "        rows.append(row)\n",
    "    df = df.append(pd.DataFrame(rows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T02:39:06.681336Z",
     "start_time": "2020-07-15T02:39:06.583727Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('results_linear_ordered.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secuencia de elementos repetidos\n",
    "\n",
    "Se crean las siguientes variaciones de secuencias:\n",
    "\n",
    "1. Secuencia de 3 elementos repetidos con step de 1\n",
    "2. Secuencia de 3 elementos repetidos con step de 3\n",
    "3. Secuencia de 3 elementos repetidos con step de $\\frac{th}{4}$\n",
    "4. Secuencia de $\\frac{th}{4}$ elementos repetidos con step aleatorio entre 4 y $th$\n",
    "\n",
    "Ademas para cada una de estas, existen dos tama単o: el tama単o de la tabla y 3 veces el tama単o de la tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T01:22:55.835231Z",
     "start_time": "2020-07-15T01:22:55.805714Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['hash', 'original_size', 'final_size', 'caso',\n",
    "                           'repeticiones', 'step_size', 'oversize', 'comparaciones', 'tamano', 'tiempos', 'tiempo_total'])\n",
    "\n",
    "casos_repetidos_3 = list(Path(DATA_DIR).glob('repeated_3*'))\n",
    "casos_repetidos_quarter = list(Path(DATA_DIR).glob('repeated_quarter*'))\n",
    "\n",
    "arr_casos_repetidos_3 = [{caso.stem: np.load(caso, allow_pickle=True)} for caso in casos_repetidos_3]\n",
    "arr_casos_repetidos_quarter = [{caso.stem: np.load(caso, allow_pickle=True)} for caso in casos_repetidos_quarter]\n",
    "\n",
    "casos_repetidos_3, casos_repetidos_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T01:48:11.610538Z",
     "start_time": "2020-07-15T01:22:59.340860Z"
    }
   },
   "outputs": [],
   "source": [
    "for caso in tqdm(arr_casos_repetidos_3):\n",
    "    tipo_caso, arrs = list(caso.items())[0]\n",
    "    rows = []\n",
    "    \n",
    "    tipo_caso = tipo_caso.split('_')\n",
    "    \n",
    "    type_name = 'repeated'\n",
    "    \n",
    "    num_repeats = tipo_caso[1]\n",
    "    step_size = tipo_caso[2]\n",
    "    \n",
    "    if tipo_caso[-1] == 'oversize':\n",
    "        oversize = 1\n",
    "    else:\n",
    "        oversize = 0\n",
    "    \n",
    "    for arr in tqdm(arrs):\n",
    "        l_hashes = [LinearHash(size=s, update_size=True) for s in sizes]\n",
    "        for lh in tqdm(l_hashes):\n",
    "            lh.run_experiment(arr)\n",
    "            total_times, individual_times, original_size, final_size, comp = lh.get_results()\n",
    "\n",
    "            row = {\n",
    "                'hash': 'lineal', \n",
    "                'original_size': original_size,\n",
    "                'final_size' : final_size,\n",
    "                'caso': type_name, \n",
    "                'repeticiones' : num_repeats, \n",
    "                'step_size' : step_size, \n",
    "                'oversize' : oversize,\n",
    "                'comparaciones':comp,\n",
    "                'tamano': len(arr), \n",
    "                'tiempos': individual_times, \n",
    "                'tiempo_total': total_times\n",
    "            }\n",
    "            \n",
    "        rows.append(row)\n",
    "    df = df.append(pd.DataFrame(rows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T01:49:54.150434Z",
     "start_time": "2020-07-15T01:49:53.916985Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('results_linear_repeated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:00:29.919Z"
    }
   },
   "outputs": [],
   "source": [
    "# for caso in tqdm(arr_casos_repetidos_quarter):\n",
    "#     tipo_caso, arrs = list(caso.items())[0]\n",
    "#     rows = []\n",
    "    \n",
    "#     tipo_caso = tipo_caso.split('_')\n",
    "    \n",
    "#     type_name = 'repeated'\n",
    "    \n",
    "#     num_repeats = tipo_caso[1]\n",
    "#     step_size = tipo_caso[2]\n",
    "    \n",
    "#     if tipo_caso[-1] == 'oversize':\n",
    "#         oversize = 1\n",
    "#     else:\n",
    "#         oversize = 0\n",
    "    \n",
    "#     for arr in tqdm(arrs):\n",
    "#         l_hashes = [LinearHash(size=s, update_size=True) for s in sizes]\n",
    "#         for lh in tqdm(l_hashes):\n",
    "#             lh.run_experiment(arr)\n",
    "#             total_times, individual_times, original_size, final_size = lh.get_results()\n",
    "\n",
    "#             row = {\n",
    "#                 'hash': 'lineal', \n",
    "#                 'original_size': original_size,\n",
    "#                 'final_size' : final_size,\n",
    "#                 'caso': type_name, \n",
    "#                 'repeticiones' : num_repeats, \n",
    "#                 'step_size' : step_size, \n",
    "#                 'oversize' : oversize,\n",
    "#                 'tamano': len(arr), \n",
    "#                 'tiempos': individual_times, \n",
    "#                 'tiempo_total': total_times\n",
    "#             }\n",
    "            \n",
    "#         rows.append(row)\n",
    "#     df = df.append(pd.DataFrame(rows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secuencia de elementos aleatorias\n",
    "\n",
    "Se crean las siguientes variaciones de secuencias:\n",
    "\n",
    "1. Secuencias aleatorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T21:54:49.827378Z",
     "start_time": "2020-07-14T21:54:49.822321Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['hash', 'original_size', 'final_size', 'caso',\n",
    "                           'caracteristica', 'tamano', 'oversize', 'comparaciones', 'tiempos', \n",
    "                           'tiempo_total'])\n",
    "\n",
    "casos_rand = list(Path(DATA_DIR).glob('random*'))\n",
    "arr_casos_rand = [{caso.stem: np.load(caso, allow_pickle=True)} for caso in casos_rand]\n",
    "casos_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-14T20:39:59.205Z"
    }
   },
   "outputs": [],
   "source": [
    "for caso in tqdm(arr_casos_rand):\n",
    "    tipo_caso, arrs = list(caso.items())[0]\n",
    "    rows = []\n",
    "    \n",
    "    tipo_caso = tipo_caso.split('_')\n",
    "    \n",
    "    type_name = 'random'\n",
    "    \n",
    "    caracteristica = tipo_caso[1]\n",
    "    \n",
    "    if tipo_caso[-1] == 'oversize':\n",
    "        oversize = 1\n",
    "    else:\n",
    "        oversize = 0\n",
    "        \n",
    "    for arr in tqdm(arrs):\n",
    "        l_hashes = [LinearHash(size=s, update_size=True) for s in sizes]\n",
    "        for dh in tqdm(l_hashes):\n",
    "            dh.run_experiment(arr)\n",
    "            total_times, individual_times, original_size, final_size, comp = dh.get_results()\n",
    "\n",
    "            row = {\n",
    "                'hash': 'lineal', \n",
    "                'original_size': original_size,\n",
    "                'final_size' : final_size,\n",
    "                'caso': tipo_caso, \n",
    "                'caracteristica': caracteristica,\n",
    "                'tamano': len(arr), \n",
    "                'oversize': oversize,\n",
    "                'comparaciones': comp, \n",
    "                'tiempos': individual_times, \n",
    "                'tiempo_total': total_times \n",
    "            }\n",
    "            \n",
    "        rows.append(row)\n",
    "    df = df.append(pd.DataFrame(rows), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-14T20:39:59.207Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('results_linear_random.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
